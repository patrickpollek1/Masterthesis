{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe708d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import r2_score as sklearn_r2_score\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86acb267",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = pd.read_csv('../../datasets/Admission/X_train.csv',index_col=0)  \n",
    "X_test = pd.read_csv('../../datasets/Admission/X_test.csv',index_col=0)  \n",
    "y_train = pd.read_csv('../../datasets/Admission/y_train.csv',index_col=0)  \n",
    "y_test = pd.read_csv('../../datasets/Admission/y_test.csv',index_col=0)\n",
    "# Specify the split ratio. For example, let's use 80% for training and 20% for validation\n",
    "split_ratio = 0.2\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=split_ratio, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a884a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310d2f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, hidden_layers, hidden_units, dropout, dropout_array, input_dim, output_dim, activation=nn.ReLU(),norm=False):\n",
    "        if hidden_layers != len(hidden_units):\n",
    "            print(\"Error: wrong size of hidden_layers or hidden_units\")\n",
    "            return\n",
    "        layers = []\n",
    "        i = 0\n",
    "        if norm:\n",
    "            layers.append(nn.BatchNorm1d(input_dim))\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        layers.append(nn.Linear(input_dim, hidden_units[i]))\n",
    "        layers.append(activation)\n",
    "        if dropout:\n",
    "            layers.append(nn.Dropout(dropout_array[i]))\n",
    "\n",
    "        for _ in range(hidden_layers - 1):\n",
    "            i += 1\n",
    "            layers.append(nn.Linear(hidden_units[i-1], hidden_units[i]))\n",
    "            layers.append(activation)\n",
    "            if dropout:\n",
    "                layers.append(nn.Dropout(dropout_array[i]))\n",
    "\n",
    "        layers.append(nn.Linear(hidden_units[-1], output_dim))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d4c04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={'batch_size': 8,\n",
    "             'lr': 5e-05,\n",
    "             'num_epochs': 300,\n",
    "             'hidden_layers': 3,\n",
    "             'hidden_units': [128, 16, 32],\n",
    "             'dropout': False,\n",
    "             'dropout_array': [0.5262243916801222, 0.17160622713412305, 0.28392396173952034],\n",
    "             'activation': nn.ReLU(),\n",
    "             'norm': True,\n",
    "             'patience': 20\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3470ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train_scaled.shape[1]\n",
    "output_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e0d5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(torch.Tensor(X_train_scaled), torch.Tensor(y_train.to_numpy()))\n",
    "val_ds = TensorDataset(torch.Tensor(X_val_scaled), torch.Tensor(y_val.to_numpy()))\n",
    "\n",
    "test_ds = TensorDataset(torch.Tensor(X_test_scaled), torch.Tensor(y_test.to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657dc77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=config[\"batch_size\"])\n",
    "\n",
    "test_loader = DataLoader(test_ds, batch_size=config[\"batch_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6f1db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(hidden_layers=config[\"hidden_layers\"], hidden_units=config[\"hidden_units\"], dropout=config[\"dropout\"], dropout_array=config[\"dropout_array\"], input_dim=input_dim, output_dim=output_dim, activation=config[\"activation\"], norm=config[\"norm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340c897d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        \n",
    "    def forward(self,yhat,y):\n",
    "        return torch.sqrt(self.mse(yhat,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0158fc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = RMSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=config[\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf162d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59011f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(net,input_size=(7,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e574d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(net, train_loader, criterion, optimizer, device):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device).view(-1, 1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    return train_loss / len(train_loader), net\n",
    "\n",
    "\n",
    "def test_net(net, test_loader, criterion, device):\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device).view(-1, 1)\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    return test_loss / len(test_loader)\n",
    "\n",
    "\n",
    "def train(config):\n",
    "    train_loader = DataLoader(train_ds, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=config[\"batch_size\"])\n",
    "    net = Net(hidden_layers=config[\"hidden_layers\"], hidden_units=config[\"hidden_units\"], dropout=config[\"dropout\"], dropout_array=config[\"dropout_array\"], input_dim=input_dim, output_dim=output_dim, activation=config[\"activation\"], norm=config[\"norm\"])\n",
    "    criterion = RMSELoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=config[\"lr\"])\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    net.to(device)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience = config['patience']\n",
    "    early_stop = False\n",
    "\n",
    "    for epoch in range(config[\"num_epochs\"]):\n",
    "        train_loss,net = train_net(net, train_loader, criterion, optimizer, device)\n",
    "        val_loss = test_net(net, val_loader, criterion, device)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{config['num_epochs']}], Train Loss: {train_loss:.4f}, Test Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience = 10\n",
    "        else:\n",
    "            patience -= 1\n",
    "            if patience == 0:\n",
    "                print(\"Early stopping...\")\n",
    "                early_stop = True\n",
    "                break\n",
    "\n",
    "    if not early_stop:\n",
    "        print(\"Training complete.\")\n",
    "\n",
    "    return train_losses, val_losses, net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0876d5a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_losses, val_losses, mod = train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccf07ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train_losses, val_losses):\n",
    "    plt.plot(train_losses, label=\"Train Loss\")\n",
    "    plt.plot(val_losses, label=\"val Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2443d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4afb963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(net, data_loader, device):\n",
    "    net.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in data_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device).view(-1, 1)\n",
    "            outputs = net(inputs)\n",
    "            y_true.extend(targets.cpu().numpy())\n",
    "            y_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "    plt.scatter(y_true, y_pred)\n",
    "    plt.xlabel(\"True Values\")\n",
    "    plt.ylabel(\"Predictions\")\n",
    "    plt.show()\n",
    "\n",
    "def r_squared(y_true, y_pred):\n",
    "    y_bar = np.mean(y_true)\n",
    "    ss_tot = np.sum((y_true - y_bar) ** 2)\n",
    "    ss_res = np.sum((y_true - y_pred) ** 2)\n",
    "    r2 = 1 - (ss_res / ss_tot)\n",
    "    return r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae959db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_losses, test_losses = train(config)\n",
    "plot_losses(train_losses, val_losses)\n",
    "plot_predictions(mod, test_loader, device)\n",
    "y_true = y_test\n",
    "y_pred = mod(torch.Tensor(X_test_scaled).to(device)).cpu().detach().numpy()\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "print(\"R^2 score:\", r2)\n",
    "y_train_tensor = torch.Tensor(y_train.values).to(device)\n",
    "y_val_tensor = torch.Tensor(y_val.values).to(device)\n",
    "y_test_tensor = torch.Tensor(y_test.values).to(device)\n",
    "print(\"Train_loss:\",criterion(mod(torch.Tensor(X_train_scaled).to(device)),y_train_tensor).item())\n",
    "print(\"Validation_loss:\",criterion(mod(torch.Tensor(X_val_scaled).to(device)),y_val_tensor).item())\n",
    "print(\"Test_loss:\",criterion(mod(torch.Tensor(X_test_scaled).to(device)),y_test_tensor).item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22211193",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mod, '../../Models/admission_model_72')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d60a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import LayerConductance\n",
    "from captum.attr import NeuronConductance\n",
    "from captum.attr import ShapleyValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587ffdae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a1153e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = mod.to(device)\n",
    "x_test_tensor = torch.Tensor(X_test_scaled).requires_grad_().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69d8656",
   "metadata": {},
   "outputs": [],
   "source": [
    "ig = IntegratedGradients(mod)\n",
    "attr, delta = ig.attribute(x_test_tensor, return_convergence_delta=True)\n",
    "attr = attr.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885996f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(attr, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4463bcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper method to print importances and visualize distribution\n",
    "def visualize_importances(feature_names, importances, title=\"Average Feature Importances\", plot=True, axis_title=\"Features\"):\n",
    "    print(title)\n",
    "    for i in range(len(feature_names)):\n",
    "        print(feature_names[i], \": \", '%.4f'%(importances[i]))\n",
    "    x_pos = (np.arange(len(feature_names)))\n",
    "    if plot:\n",
    "        plt.figure(figsize=(12,6))\n",
    "        plt.bar(x_pos, importances, align='center')\n",
    "        plt.xticks(x_pos, feature_names, wrap=True)\n",
    "        plt.xlabel(axis_title)\n",
    "        plt.title(title)\n",
    "visualize_importances(df.columns, np.mean(attr, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c017a459",
   "metadata": {},
   "outputs": [],
   "source": [
    "svs = ShapleyValues(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f8be43",
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_2 = svs.attribute(x_test_tensor)\n",
    "attr_2 = attr_2.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c806f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(attr_2, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16507a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_importances(df.columns, np.mean(attr_2, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0c9eee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
