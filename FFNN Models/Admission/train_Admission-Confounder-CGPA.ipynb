{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50efe291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from ray.tune.schedulers import PopulationBasedTraining\n",
    "from sklearn.model_selection import KFold\n",
    "from ray.tune.integration.pytorch_lightning import TuneReportCallback\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import r2_score as sklearn_r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62affd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./cleaned_datasets/admission_data.csv',index_col=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13c7056",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa59850",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.pop('Chance of Admit ')\n",
    "X = df\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3047fe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ffc16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_with_con = X_train.drop(columns=['CGPA'])\n",
    "X_test_with_con = X_test.drop(columns=['CGPA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1b35fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_with_con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869952e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_with_con)\n",
    "X_test_scaled = scaler.transform(X_test_with_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe129af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        \n",
    "    def forward(self,yhat,y):\n",
    "        return torch.sqrt(self.mse(yhat,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f77c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, hidden_layers, hidden_units, dropout, dropout_array, input_dim, output_dim, activation=nn.ReLU(),norm=False):\n",
    "        if hidden_layers != len(hidden_units):\n",
    "            print(\"Error: wrong size of hidden_layers or hidden_units\")\n",
    "            return\n",
    "        layers = []\n",
    "        i = 0\n",
    "        if norm:\n",
    "            layers.append(nn.BatchNorm1d(input_dim))\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        layers.append(nn.Linear(input_dim, hidden_units[i]))\n",
    "        layers.append(activation)\n",
    "        if dropout:\n",
    "            layers.append(nn.Dropout(dropout_array[i]))\n",
    "\n",
    "        for _ in range(hidden_layers - 1):\n",
    "            i += 1\n",
    "            layers.append(nn.Linear(hidden_units[i-1], hidden_units[i]))\n",
    "            layers.append(activation)\n",
    "            if dropout:\n",
    "                layers.append(nn.Dropout(dropout_array[i]))\n",
    "\n",
    "        layers.append(nn.Linear(hidden_units[-1], output_dim))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad4ac98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(hidden_layers=3, hidden_units=[24, 24, 24], dropout=True, dropout_array=[0.2, 0.3, 0.4], input_dim=13, output_dim=1, activation=nn.Sigmoid(),norm=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd38e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069b3594",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model,input_size=(13,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93259e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(X_train, X_test, y_train, y_test, batch_size=32):\n",
    "    # Create custom Dataset objects for train and test data\n",
    "    train_dataset = DataFrameDataset(X_train, y_train)\n",
    "    test_dataset = DataFrameDataset(X_test, y_test)\n",
    "\n",
    "    # Create DataLoaders for train and test data\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "class DataFrameDataset(Dataset):\n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = torch.tensor(X_data, dtype=torch.float32)\n",
    "        self.y_data = torch.tensor(y_data, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X_data[idx], self.y_data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bd38fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def cross_val_train(config, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits)\n",
    "    r2_scores = []\n",
    "    rmse_scores = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X_train_scaled, y_train.values):\n",
    "        X_train_cv, X_test_cv = X_train_scaled[train_index], X_train_scaled[test_index]\n",
    "        y_train_cv, y_test_cv = y_train.values[train_index], y_train.values[test_index]\n",
    "\n",
    "        train_loader, test_loader = create_dataloader(X_train_cv, X_test_cv, y_train_cv, y_test_cv, batch_size=config[\"batch_size\"])\n",
    "\n",
    "        input_dim = X_train_cv.shape[1]\n",
    "        output_dim = 1\n",
    "        net = Net(hidden_layers=config[\"hidden_layers\"], hidden_units=config[\"hidden_units\"], dropout=config[\"dropout\"], dropout_array=config[\"dropout_array\"], input_dim=input_dim, output_dim=output_dim, activation=config[\"activation\"], norm=config[\"norm\"])\n",
    "\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        net.to(device)\n",
    "\n",
    "        criterion = RMSELoss()\n",
    "        optimizer = optim.Adam(net.parameters(), lr=config[\"lr\"])\n",
    "\n",
    "        for epoch in range(config[\"epochs\"]):\n",
    "            running_loss = 0.0\n",
    "            for i, (inputs, labels) in enumerate(train_loader):\n",
    "                inputs, labels = inputs.to(device), labels.to(device).view(-1, 1)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "            \n",
    "\n",
    "        with torch.no_grad():\n",
    "            test_loss = 0.0\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device).view(-1, 1)\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss += loss.item()\n",
    "\n",
    "            y_pred = net(torch.Tensor(X_test_cv).to(device)).cpu().numpy()\n",
    "            r2_scores.append(sklearn_r2_score(y_test_cv, y_pred))\n",
    "            rmse_scores.append(np.sqrt(mean_squared_error(y_test_cv, y_pred)))\n",
    "            tune.report(r2_curr=sklearn_r2_score(y_test_cv, y_pred),loss_curr=np.sqrt(mean_squared_error(y_test_cv, y_pred)))\n",
    "            #print(r2_scores)\n",
    "            #print(rmse_scores)\n",
    "\n",
    "    avg_r2 = np.mean(r2_scores)\n",
    "    avg_rmse = np.mean(rmse_scores)\n",
    "    tune.report(loss=avg_rmse,train_loss=running_loss,r2_score=avg_r2,r2_curr=r2_scores[-1])\n",
    "\n",
    "    #return avg_rmse\n",
    "\n",
    "#best_config = {'batch_size': 8, 'lr': 0.00035262507645898283, 'epochs': 500, 'hidden_layers': 3, 'hidden_units': [128, 128, 64], 'dropout': False, 'dropout_array': [0.39233452918726697, 0.3225943639867505, 0.6472032609256847], 'activation': nn.ReLU(), 'norm': False}\n",
    "\n",
    "#avg_r2, avg_rmse = cross_val_train(best_config)\n",
    "#print(f\"Average R2 score: {avg_r2}\")\n",
    "#print(f\"Average RMSE: {avg_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bde24c",
   "metadata": {},
   "outputs": [],
   "source": [
    " train_ds = TensorDataset(torch.Tensor(X_train_scaled), torch.Tensor(y_train.to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466db5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d65db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ee6058",
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b490646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hidden_units(hidden_layers):\n",
    "    return np.random.choice(a=[16,32,64,128], size=hidden_layers).tolist()\n",
    "\n",
    "search_space = {\n",
    "    \"batch_size\": tune.choice([8,16,32, 64, 128]),\n",
    "    \"lr\": tune.loguniform(1e-7, 1e-2),\n",
    "    \"epochs\": tune.choice([25,50, 100, 150,300,500]),\n",
    "    #\"epochs\": tune.choice([25]),\n",
    "    \"hidden_layers\": tune.randint(1, 4),\n",
    "    \"hidden_units\": tune.sample_from(lambda spec: generate_hidden_units(spec.config.hidden_layers)),\n",
    "    \"dropout\": tune.choice([True, False]),\n",
    "    \"dropout_array\": tune.sample_from(lambda spec: np.random.uniform(low=0.4, high=0.6, size=spec.config.hidden_layers).tolist()),\n",
    "    \"activation\": tune.choice([nn.ReLU()]),\n",
    "    \"norm\": tune.choice([True, False])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f4a02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = ASHAScheduler(metric=\"r2_curr\", mode=\"max\", grace_period=2, reduction_factor=2)\n",
    "reporter = CLIReporter(metric_columns=[\"loss\", \"training_iteration\",\"train_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b097339",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "analysis = tune.run(\n",
    "        cross_val_train,\n",
    "        resources_per_trial={\"cpu\": 8, \"gpu\": 1 if torch.cuda.is_available() else 0},\n",
    "        config=search_space,\n",
    "        num_samples=100,\n",
    "        scheduler=scheduler,\n",
    "        progress_reporter=reporter)\n",
    "\n",
    "print(\"Best hyperparameters found were: \", analysis.get_best_config(metric=\"r2_score\", mode=\"max\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd5f05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.results_df.sort_values(by=['r2_score', 'loss'],na_position='first').tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe72d01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_config={'batch_size': 16, 'lr': 0.000157\t, 'epochs': 500, 'hidden_layers': 1, 'hidden_units': [128], 'dropout': False, 'dropout_array': [0.5262243916801222, 0.17160622713412305, 0.28392396173952034], 'activation': nn.ReLU(), 'norm': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faf357f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_config.update({\"patience\":10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deca4cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94440728",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def cross_val_train_2(config, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits)\n",
    "    r2_scores = []\n",
    "    rmse_scores = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X_train_scaled, y_train.values):\n",
    "        X_train_cv, X_test_cv = X_train_scaled[train_index], X_train_scaled[test_index]\n",
    "        y_train_cv, y_test_cv = y_train.values[train_index], y_train.values[test_index]\n",
    "\n",
    "        train_loader, test_loader = create_dataloader(X_train_cv, X_test_cv, y_train_cv, y_test_cv, batch_size=config[\"batch_size\"])\n",
    "\n",
    "        input_dim = X_train_cv.shape[1]\n",
    "        output_dim = 1\n",
    "        net = Net(hidden_layers=config[\"hidden_layers\"], hidden_units=config[\"hidden_units\"], dropout=config[\"dropout\"], dropout_array=config[\"dropout_array\"], input_dim=input_dim, output_dim=output_dim, activation=config[\"activation\"], norm=config[\"norm\"])\n",
    "\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        net.to(device)\n",
    "\n",
    "        criterion = RMSELoss()\n",
    "        optimizer = optim.Adam(net.parameters(), lr=config[\"lr\"])\n",
    "\n",
    "        for epoch in range(config[\"epochs\"]):\n",
    "            running_loss = 0.0\n",
    "            for i, (inputs, labels) in enumerate(train_loader):\n",
    "                inputs, labels = inputs.to(device), labels.to(device).view(-1, 1)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "            \n",
    "\n",
    "        with torch.no_grad():\n",
    "            test_loss = 0.0\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device).view(-1, 1)\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss += loss.item()\n",
    "\n",
    "            y_pred = net(torch.Tensor(X_test_cv).to(device)).cpu().numpy()\n",
    "            r2_scores.append(sklearn_r2_score(y_test_cv, y_pred))\n",
    "            rmse_scores.append(np.sqrt(mean_squared_error(y_test_cv, y_pred)))\n",
    "            #print(r2_scores)\n",
    "            #print(rmse_scores)\n",
    "\n",
    "    avg_r2 = np.mean(r2_scores)\n",
    "    avg_rmse = np.mean(rmse_scores)\n",
    "\n",
    "    return avg_r2, avg_rmse\n",
    "avg_r2, avg_rmse = cross_val_train_2(best_config)\n",
    "print(f\"Average R2 score: {avg_r2}\")\n",
    "print(f\"Average RMSE: {avg_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038c0000",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skopt import gp_minimize\n",
    "\n",
    "fixed_config = {\n",
    "    'hidden_layers': 1,\n",
    " 'hidden_units': [128],\n",
    " 'dropout': False,\n",
    " 'dropout_array': [0.38283509966903684,\n",
    "  0.14655095633529086,\n",
    "  0.5393755103727268],\n",
    " 'activation': nn.ReLU(),\n",
    " 'norm': True\n",
    "}\n",
    "\n",
    "# The objective function to minimize (negative R^2)\n",
    "def objective(params):\n",
    "    batch_size, lr, epochs = params\n",
    "    config = {'batch_size': int(batch_size), 'lr': lr, 'epochs': int(epochs)}\n",
    "    config.update(fixed_config)\n",
    "\n",
    "    r2, rmse = cross_val_train_2(config)\n",
    "    return rmse  # Minimize negative R^2 to maximize R^2\n",
    "\n",
    "# Hyperparameter search space\n",
    "space = [\n",
    "    (8, 256),  # batch_size\n",
    "    (1e-4, 1e-2, 'log-uniform'),  # lr\n",
    "    (30, 250)  # epochs\n",
    "]\n",
    "\n",
    "# Bayesian optimization using Gaussian Process\n",
    "result = gp_minimize(\n",
    "    func=objective,\n",
    "    dimensions=space,\n",
    "    n_calls=100,  # Number of iterations\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Print the optimized hyperparameters\n",
    "print(\"Best hyperparameters found:\")\n",
    "print(\"Batch size:\", result.x[0])\n",
    "print(\"Learning rate:\", result.x[1])\n",
    "print(\"Epochs:\", result.x[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d194c14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
